{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [],
      "dockerImageVersionId": 30674,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "name": "GAN_AlanNorcott",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Alanvnorcott/FashionGeneratorGAN/blob/main/GAN_AlanNorcott.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "assert sys.version_info >= (3, 7)\n",
        "\n",
        "\n",
        "from packaging import version\n",
        "import sklearn\n",
        "assert version.parse(sklearn.__version__) >= version.parse(\"1.0.1\")\n",
        "\n",
        "\n",
        "import tensorflow as tf\n",
        "assert version.parse(tf.__version__) >= version.parse(\"2.8.0\")\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "execution": {
          "iopub.status.busy": "2024-04-03T23:47:37.367744Z",
          "iopub.execute_input": "2024-04-03T23:47:37.368021Z",
          "iopub.status.idle": "2024-04-03T23:47:52.601255Z",
          "shell.execute_reply.started": "2024-04-03T23:47:37.367997Z",
          "shell.execute_reply": "2024-04-03T23:47:52.600433Z"
        },
        "trusted": true,
        "id": "mFnOfy6XNrAy",
        "outputId": "e9d2961b-95bb-4b61-f155-b1ae0edb2243"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "text": "2024-04-03 23:47:40.642267: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-04-03 23:47:40.642369: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-04-03 23:47:40.809669: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load the fashion MNIST dataset, scale it, and split it into a training set, a validation set, and a test set"
      ],
      "metadata": {
        "id": "xVQoThyaNrA0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fashion_mnist = tf.keras.datasets.fashion_mnist.load_data()\n",
        "(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist\n",
        "X_train_full = X_train_full.astype(np.float32) / 255\n",
        "X_test = X_test.astype(np.float32) / 255\n",
        "X_train, X_valid = X_train_full[:-5000], X_train_full[-5000:]\n",
        "y_train, y_valid = y_train_full[:-5000], y_train_full[-5000:]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-03T23:47:52.602624Z",
          "iopub.execute_input": "2024-04-03T23:47:52.603455Z",
          "iopub.status.idle": "2024-04-03T23:47:53.4622Z",
          "shell.execute_reply.started": "2024-04-03T23:47:52.60343Z",
          "shell.execute_reply": "2024-04-03T23:47:53.461385Z"
        },
        "trusted": true,
        "id": "Y5fdjzxSNrA1",
        "outputId": "9f1fba84-26ce-4a1a-9d01-e573960992f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n\u001b[1m29515/29515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\nDownloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n\u001b[1m26421880/26421880\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\nDownloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n\u001b[1m5148/5148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\nDownloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n\u001b[1m4422102/4422102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(42)  # extra code – ensures reproducibility on CPU\n",
        "\n",
        "\n",
        "codings_size = 10\n",
        "\n",
        "\n",
        "Dense = tf.keras.layers.Dense\n",
        "generator = tf.keras.Sequential([\n",
        "    Dense(100, activation=\"relu\", kernel_initializer=\"he_normal\"),\n",
        "    Dense(150, activation=\"relu\", kernel_initializer=\"he_normal\"),\n",
        "    Dense(28 * 28, activation=\"sigmoid\"),\n",
        "    tf.keras.layers.Reshape([28, 28])\n",
        "])\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-03T23:47:53.463223Z",
          "iopub.execute_input": "2024-04-03T23:47:53.463487Z",
          "iopub.status.idle": "2024-04-03T23:47:53.477515Z",
          "shell.execute_reply.started": "2024-04-03T23:47:53.463466Z",
          "shell.execute_reply": "2024-04-03T23:47:53.476412Z"
        },
        "trusted": true,
        "id": "gN0YzDVFNrA1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "discriminator = tf.keras.Sequential([\n",
        "    tf.keras.layers.Flatten(),\n",
        "    Dense(150, activation=\"relu\", kernel_initializer=\"he_normal\"),\n",
        "    Dense(100, activation=\"relu\", kernel_initializer=\"he_normal\"),\n",
        "    Dense(1, activation=\"sigmoid\")\n",
        "])\n",
        "gan = tf.keras.Sequential([generator, discriminator])\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-03T23:47:53.480227Z",
          "iopub.execute_input": "2024-04-03T23:47:53.481105Z",
          "iopub.status.idle": "2024-04-03T23:47:53.494655Z",
          "shell.execute_reply.started": "2024-04-03T23:47:53.48107Z",
          "shell.execute_reply": "2024-04-03T23:47:53.493709Z"
        },
        "trusted": true,
        "id": "PsIGcz78NrA1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "discriminator.compile(loss=\"binary_crossentropy\", optimizer=\"rmsprop\")\n",
        "discriminator.trainable = False\n",
        "gan.compile(loss=\"binary_crossentropy\", optimizer=\"rmsprop\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-03T23:47:53.495776Z",
          "iopub.execute_input": "2024-04-03T23:47:53.49609Z",
          "iopub.status.idle": "2024-04-03T23:47:54.290093Z",
          "shell.execute_reply.started": "2024-04-03T23:47:53.496026Z",
          "shell.execute_reply": "2024-04-03T23:47:54.289231Z"
        },
        "trusted": true,
        "id": "XwG1qph0NrA1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "dataset = tf.data.Dataset.from_tensor_slices(X_train).shuffle(1000)\n",
        "dataset = dataset.batch(batch_size, drop_remainder=True).prefetch(1)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-03T23:47:54.291076Z",
          "iopub.execute_input": "2024-04-03T23:47:54.291322Z",
          "iopub.status.idle": "2024-04-03T23:47:56.434867Z",
          "shell.execute_reply.started": "2024-04-03T23:47:54.291301Z",
          "shell.execute_reply": "2024-04-03T23:47:56.434061Z"
        },
        "trusted": true,
        "id": "SGxVxjgYNrA2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_multiple_images(images, n_cols=None):\n",
        "    n_cols = n_cols or len(images)\n",
        "    n_rows = (len(images) - 1) // n_cols + 1\n",
        "    if images.shape[-1] == 1:\n",
        "        images = images.squeeze(axis=-1)\n",
        "    plt.figure(figsize=(n_cols, n_rows))\n",
        "    for index, image in enumerate(images):\n",
        "        plt.subplot(n_rows, n_cols, index + 1)\n",
        "        plt.imshow(image, cmap=\"binary\")\n",
        "        plt.axis(\"off\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-03T23:47:56.436023Z",
          "iopub.execute_input": "2024-04-03T23:47:56.436333Z",
          "iopub.status.idle": "2024-04-03T23:47:56.442731Z",
          "shell.execute_reply.started": "2024-04-03T23:47:56.43631Z",
          "shell.execute_reply": "2024-04-03T23:47:56.441729Z"
        },
        "trusted": true,
        "id": "egrcLFQzNrA2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_gan(gan, dataset, batch_size, codings_size, n_epochs):\n",
        "    generator, discriminator = gan.layers\n",
        "    for epoch in range(n_epochs):\n",
        "        print(f\"Epoch {epoch + 1}/{n_epochs}\")  # extra code\n",
        "        for X_batch in dataset:\n",
        "            # phase 1 - training the discriminator\n",
        "            noise = tf.random.normal(shape=[batch_size, codings_size])\n",
        "            generated_images = generator(noise)\n",
        "            X_fake_and_real = tf.concat([generated_images, X_batch], axis=0)\n",
        "            y1 = tf.constant([[0.]] * batch_size + [[1.]] * batch_size)\n",
        "            discriminator.train_on_batch(X_fake_and_real, y1)\n",
        "            # phase 2 - training the generator\n",
        "            noise = tf.random.normal(shape=[batch_size, codings_size])\n",
        "            y2 = tf.constant([[1.]] * batch_size)\n",
        "            gan.train_on_batch(noise, y2)\n",
        "        # extra code — plot images during training\n",
        "        plot_multiple_images(generated_images.numpy(), 8)\n",
        "        plt.show()\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-03T23:47:56.443811Z",
          "iopub.execute_input": "2024-04-03T23:47:56.444087Z",
          "iopub.status.idle": "2024-04-03T23:47:56.460012Z",
          "shell.execute_reply.started": "2024-04-03T23:47:56.444059Z",
          "shell.execute_reply": "2024-04-03T23:47:56.459263Z"
        },
        "trusted": true,
        "id": "KPEO9lgSNrA2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Reducing the number of epochs from 50 to 35\n",
        "## Otherwise getting an out-of-memory error\n"
      ],
      "metadata": {
        "id": "gHtl_MMVNrA2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#train_gan(gan, dataset, batch_size, codings_size, n_epochs=50)\n",
        "train_gan(gan, dataset, batch_size, codings_size, n_epochs=5)\n",
        "tf.random.set_seed(42)  # extra code – ensures reproducibility on CPU\n",
        "\n",
        "\n",
        "codings = tf.random.normal(shape=[batch_size, codings_size])\n",
        "generated_images = generator.predict(codings)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-03T23:47:56.460995Z",
          "iopub.execute_input": "2024-04-03T23:47:56.46135Z"
        },
        "trusted": true,
        "id": "bdlu9ntINrA2",
        "outputId": "457d7542-8c94-4779-996c-c42c09426a7f"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Epoch 1/35\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py:74: UserWarning: The model does not have any trainable weights.\n  warnings.warn(\"The model does not have any trainable weights.\")\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1712188077.877482      88 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\nW0000 00:00:1712188077.893733      88 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "\n",
        "\n",
        "IMAGES_PATH = Path() / \"images\" / \"generative\"\n",
        "IMAGES_PATH.mkdir(parents=True, exist_ok=True)\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "aJGYCps-NrA2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
        "    path = IMAGES_PATH / f\"{fig_id}.{fig_extension}\"\n",
        "    if tight_layout:\n",
        "        plt.tight_layout()\n",
        "    plt.savefig(path, format=fig_extension, dpi=resolution)\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "YLjfzpfYNrA3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# extra code – this cell generates and saves Figure 17–15\n",
        "plot_multiple_images(generated_images, 8)\n",
        "save_fig(\"gan_generated_images_plot\", tight_layout=False)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "J1fm6fFkNrA3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Deep Convolutional GAN"
      ],
      "metadata": {
        "id": "7BAM2JYLNrA3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(42)  # extra code – ensures reproducibility on CPU\n",
        "codings_size = 100\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "CAZFIZsCNrA3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generator = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(7 * 7 * 128),\n",
        "    tf.keras.layers.Reshape([7, 7, 128]),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Conv2DTranspose(64, kernel_size=5, strides=2,\n",
        "                                    padding=\"same\", activation=\"relu\"),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Conv2DTranspose(1, kernel_size=5, strides=2,\n",
        "                                    padding=\"same\", activation=\"tanh\"),\n",
        "])\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "A5EdNHwnNrA3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "discriminator = tf.keras.Sequential([\n",
        "    tf.keras.layers.Conv2D(64, kernel_size=5, strides=2, padding=\"same\",\n",
        "                        activation=tf.keras.layers.LeakyReLU(0.2)),\n",
        "    tf.keras.layers.Dropout(0.4),\n",
        "    tf.keras.layers.Conv2D(128, kernel_size=5, strides=2, padding=\"same\",\n",
        "                        activation=tf.keras.layers.LeakyReLU(0.2)),\n",
        "    tf.keras.layers.Dropout(0.4),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(1, activation=\"sigmoid\")\n",
        "])\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "83moqw73NrA3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gan = tf.keras.Sequential([generator, discriminator])\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "pNF9GB5ENrA3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# extra code – compiles the discrimator and the gan, as earlier\n",
        "discriminator.compile(loss=\"binary_crossentropy\", optimizer=\"rmsprop\")\n",
        "discriminator.trainable = False\n",
        "gan.compile(loss=\"binary_crossentropy\", optimizer=\"rmsprop\")\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "l7y--TQvNrA3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_dcgan = X_train.reshape(-1, 28, 28, 1) * 2. - 1. # reshape and rescale"
      ],
      "metadata": {
        "trusted": true,
        "id": "1vvHlFicNrA3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_gan(gan, dataset, batch_size, codings_size, n_epochs):\n",
        "    generator, discriminator = gan.layers\n",
        "    for epoch in range(n_epochs):\n",
        "        print(f\"Epoch {epoch + 1}/{n_epochs}\")  # extra code\n",
        "        for X_batch in dataset:\n",
        "            # phase 1 - training the discriminator\n",
        "            noise = tf.random.normal(shape=[batch_size, codings_size])\n",
        "            generated_images = generator(noise)\n",
        "            X_fake_and_real = tf.concat([generated_images, X_batch], axis=0)\n",
        "            y1 = tf.constant([[0.]] * batch_size + [[1.]] * batch_size)\n",
        "            discriminator.train_on_batch(X_fake_and_real, y1)\n",
        "            # phase 2 - training the generator\n",
        "            noise = tf.random.normal(shape=[batch_size, codings_size])\n",
        "            y2 = tf.constant([[1.]] * batch_size)\n",
        "            gan.train_on_batch(noise, y2)\n",
        "        # extra code — plot images during training\n",
        "        plot_multiple_images(generated_images.numpy(), 8)\n",
        "        plt.show()"
      ],
      "metadata": {
        "trusted": true,
        "id": "kGz3XbqtNrA3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_multiple_images(images, n_cols=None):\n",
        "    n_cols = n_cols or len(images)\n",
        "    n_rows = (len(images) - 1) // n_cols + 1\n",
        "    if images.shape[-1] == 1:\n",
        "        images = images.squeeze(axis=-1)\n",
        "    plt.figure(figsize=(n_cols, n_rows))\n",
        "    for index, image in enumerate(images):\n",
        "        plt.subplot(n_rows, n_cols, index + 1)\n",
        "        plt.imshow(image, cmap=\"binary\")\n",
        "        plt.axis(\"off\")"
      ],
      "metadata": {
        "trusted": true,
        "id": "k_ka7zLuNrA3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "# extra code – generates the dataset and trains the GAN, just like earlier\n",
        "batch_size = 32\n",
        "dataset = tf.data.Dataset.from_tensor_slices(X_train_dcgan)\n",
        "dataset = dataset.shuffle(1000)\n",
        "dataset = dataset.batch(batch_size, drop_remainder=True).prefetch(1)"
      ],
      "metadata": {
        "trusted": true,
        "id": "qAduXPQsNrA3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train_gan(gan, dataset, batch_size, codings_size, n_epochs=50)\n",
        "train_gan(gan, dataset, batch_size, codings_size, n_epochs=35)"
      ],
      "metadata": {
        "trusted": true,
        "id": "XxhgqG3nNrA3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(42)\n",
        "noise = tf.random.normal(shape=[batch_size, codings_size])\n",
        "generated_images = generator.predict(noise)\n",
        "plot_multiple_images(generated_images, 8)\n",
        "save_fig(\"dcgan_generated_images_plot\", tight_layout=False)"
      ],
      "metadata": {
        "trusted": true,
        "id": "8j5eJmuiNrA3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}